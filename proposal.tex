\section{Proposal} \label{sec:proposal}

Let us assume the resources available are fairly fixed in line with \secref{sec:resources}.
Hence we will need an arbitration committee \secref{sec:arbitration}

We promised some form of user batch which it seems likely will be needed at least initially as many users understand batch processing of images say. By batch here we should be clear we mean a BPS command line interface to something like PanDA. \secref{sec:bpsbatch}

These two items with the RSP fulfill our requirements.  RSP covers a bunch of other requirements on queries and image access \secref{sec:rsp}.


\subsection{Science Platform}\label{sec:rsp}
The RSP is now well established and is following the vision \citeds{LSE-319}.
Data Preview 0 has introduced tn early version of this to the community.

\citeds{DMTN-202} points 4 (\secref{sec:requirements}) on catalogs we can assume means a sort of Dask/Spark access to the Parquet files.  The baseline answer for catalog queries  was Qserv and but we so not have the "next to the database processing". The DAC team feel the parquet files provide a good mechanism for this and there is some effort in FY24 to implement it.{\textbf We should consider carefully what the minimum system we need here is to cover our requirements.}

We will not at this point promise extensive Dask/Spark like services but should work on that in the background with LINCC. I think we all agree this will be scientifically useful, but we need to finish construction as a priority.

\textbf{Do we agree to work with LINCC on DASK/Spark ? and promise the minimum batch system and next to the database processing  as the construction deliverable}

\subsection{Butler Gen3}

Whether Batch or RSP a butler is available with provenance information which should cover DMS-REQ-0106 and DMS-REQ-0121.

\subsection{BPS Batch }\label{sec:bpsbatch}
We set DP0.2 as an initial test of seeing how we could work with PanDA \citeds{RTN-013}
for DRP. Potentially it could also be used for Prompt Processing and user batch processing.
In fact we use the BPS front end to submit jobs and middleware which to keep BPS working with at least on other back end as well as PanDA.

It seems then the minimum promise to our batch users would be a BPS front end for job submission.
This would make it look the same as any of our internal processes.
In the end if we use Condor, Slurm, the submission would be BPS.
The job tracking of course would depend on the back end.
We should not necessarily commit to the same back end in all locations - hence USDF may be PanDA but on Google or an processing IDAC we may have a different back end.

This BPS fronted system would meet \citeds{DMTN-202} points 1-5 (\secref{sec:requirements}). The Point 4 on catalogs can be met with Qserv.
This would also cover DMS-REQ-0119, DMS-REQ-0125, DMS-REQ-0128, DMS-REQ-0123, DMS-REQ-0127.


\subsection{Arbitration or Resource Allocation Committee}\label{sec:arbitration}
As \secref{sec:resources} points out we will need an arbitration committee of some sort.
It seems this should also favor individuals from under represented  and under resourced groups though that is being proposed here for the first time.
The committee is called out in the operations plan \citedsp{RDO-018} Section 12.2 but we have as yet not created a charge for it.
This committee would at least be responsible for creating, implementing and updating  policies on at least:

\begin{itemize}
\item Requests for storage over the default allocation, either temporary or permanent.
\item Requests for large batch compute accounts at SLAC.
\item Requests for extra batch compute cycles on Google.
\item Bringing compute from another Google funded account to operate on the Rubin Object Store Cache or Science Platform.
\item Cache Optimization on Google wrt. which data sets may live entirely on Google (e.g. coadds).
\item \ldots
\end{itemize}

This would meet \citeds{DMTN-202} point 6  (\secref{sec:requirements}).

\subsection{Other catalogs}

DMS-REQ-0124: Federation with external catalogs, is a bit open ended.
Theoretically we already meet this with IVOA protocols since we could match to any IVOA service.
DAX will provide a small user catalog match to Qserv.
Other catalogs could be loaded and matched however getting a list has proved fairly inconclusive.
LINCC may again help here by coordinating IDACs to provide neighbor tables/services for other catalogs.
One notion would be to have a the Object catalog at IDACs matched to their local holdings.
We could consider migrating some of those neighbor catalogs back to USDF Qserv.

\textbf{How do we answer this fairly open requirement ? Do we say we deliver Gaia matched for construction and will work on an IDAC/LINCC service ?}
